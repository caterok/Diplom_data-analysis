import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="ClasterTeach - –ê–Ω–∞–ª–∏–∑ –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'data_preprocessed' not in st.session_state:
    st.session_state.data_preprocessed = False
if 'params_optimized' not in st.session_state:
    st.session_state.params_optimized = False
if 'clustering_done' not in st.session_state:
    st.session_state.clustering_done = False
if 'clustering_info' not in st.session_state:
    st.session_state.clustering_info = None

class DataAnalyzer:
    def __init__(self):
        self.data = None
        self.data_processed = None
        self.labels = None
        self.X_reduced = None
        self.best_params = None

    def load_data(self, file_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        try:
            self.data = pd.read_csv(file_path)


            categorical_cols = self.data.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                st.info(f"–£–¥–∞–ª–µ–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {list(categorical_cols)}")
                self.data = self.data.drop(columns=categorical_cols)


            st.session_state.data_preprocessed = False
            st.session_state.params_optimized = False
            st.session_state.clustering_done = False
            st.session_state.clustering_info = None

            return True
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")
            return False

    def analyze_missing_values(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        missing_values = self.data.isnull().sum()
        missing_percentage = (missing_values / len(self.data)) * 100

        missing_df = pd.DataFrame({
            '–ö–æ–ª–æ–Ω–∫–∞': missing_values.index,
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_values.values,
            '–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_percentage.values
        })

        missing_df = missing_df[missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤'] > 0]

        return missing_df

    def preprocess_data(self):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –º–µ–¥–∏–∞–Ω–æ–π
        self.data_processed = self.data.fillna(self.data.median())

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        data_standardized = scaler.fit_transform(self.data_processed)
        self.data_processed = pd.DataFrame(data_standardized, columns=self.data.columns)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º t-SNE –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        self.X_reduced = tsne.fit_transform(self.data_processed)

        return self.data_processed

    def optimize_dbscan(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DBSCAN —Å –ø–æ–º–æ—â—å—é –±–∞–π–µ—Å–æ–≤—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""

        # –°—ç–º–ø–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        sample_size = min(5000, len(self.X_reduced))
        if len(self.X_reduced) > sample_size:
            indices = np.random.choice(len(self.X_reduced), sample_size, replace=False)
            X_sample = self.X_reduced[indices]
        else:
            X_sample = self.X_reduced

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        dimensions = [
            Real(0.1, 10.0, name='eps'),
            Integer(5, 50, name='min_samples')
        ]

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        @use_named_args(dimensions)
        def evaluate_clustering(**params):
            eps = params['eps']
            min_samples = params['min_samples']

            try:
                db = DBSCAN(eps=eps, min_samples=min_samples).fit(X_sample)
                labels = db.labels_

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã 2 –∫–ª–∞—Å—Ç–µ—Ä–∞ (–∏—Å–∫–ª—é—á–∞—è —à—É–º)
                unique_labels = set(labels)
                n_clusters = len(unique_labels) - (1 if -1 in labels else 0)

                if n_clusters < 2 or n_clusters > 20:
                    return -1

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
                if len(unique_labels) > 1:
                    silhouette_avg = silhouette_score(X_sample, labels)
                    return -silhouette_avg  # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π —Å–∏–ª—É—ç—Ç
                else:
                    return -1
            except:
                return -1

        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–∞–π–µ—Å–æ–≤—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
        with st.spinner("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DBSCAN..."):
            try:
                res_gp = gp_minimize(
                    evaluate_clustering,
                    dimensions,
                    n_calls=30,
                    random_state=42,
                    verbose=False
                )

                self.best_params = {
                    'eps': res_gp.x[0],
                    'min_samples': res_gp.x[1]
                }

                return True
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {str(e)}")
                return False

    def apply_dbscan(self):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ DBSCAN —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        if self.best_params is None:
            st.error("–°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤!")
            return False

        try:
            db = DBSCAN(
                eps=self.best_params['eps'],
                min_samples=int(self.best_params['min_samples'])
            ).fit(self.X_reduced)

            self.labels = db.labels_

            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            n_clusters = len(set(self.labels)) - (1 if -1 in self.labels else 0)
            n_noise = list(self.labels).count(-1)

            # –í—ã—á–∏—Å–ª—è–µ–º —Å–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –±–æ–ª–µ–µ 1 –∫–ª–∞—Å—Ç–µ—Ä–∞
            if n_clusters > 1:
                silhouette = silhouette_score(self.X_reduced, self.labels)
            else:
                silhouette = 0

            clustering_info = {
                'n_clusters': n_clusters,
                'n_noise': n_noise,
                'noise_percentage': (n_noise / len(self.labels)) * 100,
                'silhouette_score': silhouette
            }

            return clustering_info

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}")
            return None

    def get_cluster_statistics(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"""
        if self.labels is None:
            return None

        cluster_stats = []

        for cluster_id in np.unique(self.labels):
            if cluster_id == -1:
                cluster_name = "–®—É–º"
            else:
                cluster_name = f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}"

            indices = np.where(self.labels == cluster_id)[0]
            size = len(indices)

            if size > 0:
                cluster_data = self.data_processed.iloc[indices]
                stats = {
                    '–ö–ª–∞—Å—Ç–µ—Ä': cluster_name,
                    '–†–∞–∑–º–µ—Ä': size,
                    '–ü—Ä–æ—Ü–µ–Ω—Ç': (size / len(self.labels)) * 100
                }

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
                for col in self.data_processed.columns[:5]:  # –ü–µ—Ä–≤—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                    stats[f'{col}_—Å—Ä–µ–¥–Ω–µ–µ'] = cluster_data[col].mean()

                cluster_stats.append(stats)

        return pd.DataFrame(cluster_stats)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
@st.cache_resource
def init_analyzer():
    return DataAnalyzer()

def main():
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    st.markdown('<h1 class="main-header"> ClasterTeach - –ê–Ω–∞–ª–∏–∑ –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö</h1>', unsafe_allow_html=True)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = init_analyzer()

    # –°–∞–π–¥–±–∞—Ä
    with st.sidebar:
        st.header(" –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
        uploaded_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª",
            type=['csv'],
            help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV"
        )

        if uploaded_file is not None:
            if st.button(" –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", key="load_data"):
                with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    if analyzer.load_data(uploaded_file):
                        st.session_state.data_loaded = True
                        st.session_state.file_name = uploaded_file.name
                        st.success(" –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
                        st.rerun()

        st.markdown("---")

        # –î–µ–º–æ –¥–∞–Ω–Ω—ã–µ
        if not st.session_state.data_loaded:
            if st.button("üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ", key="demo_data"):
                # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ
                np.random.seed(42)
                n_samples = 1000
                demo_data = pd.DataFrame({
                    '–ü—Ä–∏–∑–Ω–∞–∫_1': np.random.normal(0, 1, n_samples),
                    '–ü—Ä–∏–∑–Ω–∞–∫_2': np.random.normal(0, 1, n_samples),
                    '–ü—Ä–∏–∑–Ω–∞–∫_3': np.random.normal(0, 1, n_samples),
                    '–ü—Ä–∏–∑–Ω–∞–∫_4': np.random.normal(0, 1, n_samples),
                    '–ü—Ä–∏–∑–Ω–∞–∫_5': np.random.normal(0, 1, n_samples),
                    '–¶–µ–ª–µ–≤–∞—è_–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è': np.random.choice([0, 1], n_samples)
                })

                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
                mask = np.random.random(demo_data.shape) < 0.05
                demo_data = demo_data.mask(mask)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                import tempfile
                import os

                with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
                    demo_data.to_csv(f.name, index=False)
                    analyzer.load_data(f.name)

                st.session_state.data_loaded = True
                st.session_state.file_name = "demo_data.csv"
                st.rerun()

        # –°—Ç–∞—Ç—É—Å
        if st.session_state.data_loaded:
            st.markdown("---")
            st.success(" –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            st.info(f"–§–∞–π–ª: {st.session_state.file_name}")
            st.info(f"–†–∞–∑–º–µ—Ä: {analyzer.data.shape[0]} —Å—Ç—Ä–æ–∫, {analyzer.data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")

            if st.session_state.data_preprocessed:
                st.success(" –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            if st.session_state.params_optimized:
                st.success(" –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            if st.session_state.clustering_done:
                st.success(" –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")

    # –û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    if not st.session_state.data_loaded:
        # –≠–∫—Ä–∞–Ω –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("### –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ ClasterTeach!")
            st.markdown("""
            –î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –±–æ–∫–æ–≤—É—é –ø–∞–Ω–µ–ª—å.

            **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
            1. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            2. –¢–µ–ø–ª–æ–≤—ã–µ –∫–∞—Ä—Ç—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
            3. –î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞–∑–º–∞—Ö–∞
            4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è DBSCAN
            5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            """)

        return

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑
    st.markdown('<h2 class="section-header"> –û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö</h2>', unsafe_allow_html=True)

    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫", analyzer.data.shape[0])
    with col2:
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤", analyzer.data.shape[1])
    with col3:
        missing_total = analyzer.data.isnull().sum().sum()
        st.metric("–í—Å–µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤", missing_total)
    with col4:
        missing_percent = (missing_total / (analyzer.data.shape[0] * analyzer.data.shape[1])) * 100
        st.metric("–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤", f"{missing_percent:.1f}%")

    # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    tab1, tab2, tab3, tab4 = st.tabs([
        "–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö",
        "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤",
        "–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è",
        "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"
    ])

    with tab1:
        st.markdown('<h3 class="section-header">–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö</h3>', unsafe_allow_html=True)

        st.subheader("–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")
        st.dataframe(analyzer.data.head(10), use_container_width=True)

        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")
        st.dataframe(analyzer.data.describe(), use_container_width=True)

        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–æ–Ω–∫–∞—Ö")
        col_info = pd.DataFrame({
            '–ö–æ–ª–æ–Ω–∫–∞': analyzer.data.columns,
            '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': analyzer.data.dtypes.values,
            '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': [analyzer.data[col].nunique() for col in analyzer.data.columns]
        })
        st.dataframe(col_info, use_container_width=True)

    with tab2:
        st.markdown('<h3 class="section-header">–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π</h3>', unsafe_allow_html=True)

        missing_df = analyzer.analyze_missing_values()

        if len(missing_df) == 0:
            st.success(" –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π!")
        else:
            # –¢–∞–±–ª–∏—Ü–∞ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
            st.subheader("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º")
            st.dataframe(missing_df, use_container_width=True)

            # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–ø—É—Å–∫–æ–≤
            st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤")

            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤', '–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤'),
                horizontal_spacing=0.2
            )

            fig.add_trace(
                go.Bar(
                    x=missing_df['–ö–æ–ª–æ–Ω–∫–∞'],
                    y=missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤'],
                    name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                    marker_color='indianred'
                ),
                row=1, col=1
            )

            fig.add_trace(
                go.Bar(
                    x=missing_df['–ö–æ–ª–æ–Ω–∫–∞'],
                    y=missing_df['–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤'],
                    name='–ü—Ä–æ—Ü–µ–Ω—Ç',
                    marker_color='lightcoral'
                ),
                row=1, col=2
            )

            fig.update_xaxes(tickangle=45, row=1, col=1)
            fig.update_xaxes(tickangle=45, row=1, col=2)
            fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", row=1, col=1)
            fig.update_yaxes(title_text="–ü—Ä–æ—Ü–µ–Ω—Ç", row=1, col=2)
            fig.update_layout(height=500, showlegend=False)

            st.plotly_chart(fig, use_container_width=True)

            # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
            if st.button(" –ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –º–µ–¥–∏–∞–Ω–æ–π –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å", key="fill_missing"):
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    analyzer.preprocess_data()
                    st.session_state.data_preprocessed = True
                    st.success(" –ü—Ä–æ–ø—É—Å–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –º–µ–¥–∏–∞–Ω–æ–π!")
                    st.rerun()

    with tab3:
        st.markdown('<h3 class="section-header">–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö</h3>', unsafe_allow_html=True)

        if not st.session_state.data_preprocessed:
            st.warning(" –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∏ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤'")
        else:
            # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
            st.subheader("–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")

            corr_matrix = analyzer.data_processed.corr()

            fig = go.Figure(data=go.Heatmap(
                z=corr_matrix.values,
                x=corr_matrix.columns,
                y=corr_matrix.columns,
                colorscale='RdBu',
                zmid=0,
                hoverongaps=False
            ))

            fig.update_layout(
                height=600,
                title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞",
                xaxis_tickangle=-45
            )

            st.plotly_chart(fig, use_container_width=True)

            # –î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞–∑–º–∞—Ö–∞
            st.subheader("–î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞–∑–º–∞—Ö–∞ (Box Plots)")

            selected_cols = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                options=analyzer.data_processed.columns.tolist(),
                default=analyzer.data_processed.columns[:5].tolist() if len(analyzer.data_processed.columns) > 5 else analyzer.data_processed.columns.tolist(),
                key="boxplot_cols"
            )

            if selected_cols:
                n_cols = min(3, len(selected_cols))
                n_rows = (len(selected_cols) + n_cols - 1) // n_cols

                fig = make_subplots(
                    rows=n_rows, cols=n_cols,
                    subplot_titles=selected_cols
                )

                for i, col in enumerate(selected_cols):
                    row = i // n_cols + 1
                    col_idx = i % n_cols + 1

                    fig.add_trace(
                        go.Box(
                            y=analyzer.data_processed[col],
                            name=col,
                            boxmean='sd'
                        ),
                        row=row, col=col_idx
                    )

                fig.update_layout(
                    height=300 * n_rows,
                    showlegend=False,
                    title_text="–î–∏–∞–≥—Ä–∞–º–º—ã —Ä–∞–∑–º–∞—Ö–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º"
                )

                st.plotly_chart(fig, use_container_width=True)

            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

            selected_col = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã:",
                options=analyzer.data_processed.columns.tolist(),
                key="histogram_col"
            )

            if selected_col:
                fig = px.histogram(
                    analyzer.data_processed,
                    x=selected_col,
                    nbins=50,
                    title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {selected_col}",
                    marginal="box"
                )

                st.plotly_chart(fig, use_container_width=True)

    with tab4:
        st.markdown('<h3 class="section-header">–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è DBSCAN</h3>', unsafe_allow_html=True)

        if not st.session_state.data_preprocessed:
            st.warning(" –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∏ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤'")
        else:
            # –û–±–ª–∞—Å—Ç—å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if not st.session_state.params_optimized:
                st.info("### –®–∞–≥ 1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DBSCAN")
                st.markdown("""
                **–ß—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ:**
                1. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–π–µ—Å–æ–≤—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                2. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—Ç—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã `eps` –∏ `min_samples`
                3. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–∞–∫ –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                """)

                if st.button(" –ù–∞—á–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", type="primary", key="optimize_params"):
                    with st.spinner("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥"):
                        if analyzer.optimize_dbscan():
                            st.session_state.params_optimized = True
                            st.success(" –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")

                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                            st.markdown("### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("eps (—Ä–∞–¥–∏—É—Å)", f"{analyzer.best_params['eps']:.3f}")
                            with col2:
                                st.metric("min_samples (–º–∏–Ω. –æ–±—Ä–∞–∑—Ü–æ–≤)", int(analyzer.best_params['min_samples']))

                            st.rerun()

            # –û–±–ª–∞—Å—Ç—å –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            elif st.session_state.params_optimized and not st.session_state.clustering_done:
                st.info("### –®–∞–≥ 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
                st.markdown(f"""
                **–ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
                - **eps**: {analyzer.best_params['eps']:.3f}
                - **min_samples**: {int(analyzer.best_params['min_samples'])}
                """)

                if st.button(" –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é", type="primary", key="apply_clustering"):
                    with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏..."):
                        clustering_info = analyzer.apply_dbscan()

                        if clustering_info:
                            st.session_state.clustering_done = True
                            st.session_state.clustering_info = clustering_info
                            st.success(" –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                            st.rerun()

            # –ü–æ–∫–∞–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            if st.session_state.clustering_done and st.session_state.clustering_info:
                info = st.session_state.clustering_info

                st.success("### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

                # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", info['n_clusters'])
                with col2:
                    st.metric("–¢–æ—á–µ–∫ —à—É–º–∞", info['n_noise'])
                with col3:
                    st.metric("–ü—Ä–æ—Ü–µ–Ω—Ç —à—É–º–∞", f"{info['noise_percentage']:.1f}%")
                with col4:
                    if info['n_clusters'] > 1:
                        st.metric("–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç", f"{info['silhouette_score']:.3f}")
                    else:
                        st.metric("–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç", "N/A")

                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (t-SNE)")

                # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                viz_df = pd.DataFrame({
                    'X': analyzer.X_reduced[:, 0],
                    'Y': analyzer.X_reduced[:, 1],
                    '–ö–ª–∞—Å—Ç–µ—Ä': analyzer.labels
                })

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ —Å—Ç—Ä–æ–∫–∏
                viz_df['–ö–ª–∞—Å—Ç–µ—Ä'] = viz_df['–ö–ª–∞—Å—Ç–µ—Ä'].apply(
                    lambda x: '–®—É–º' if x == -1 else f'–ö–ª–∞—Å—Ç–µ—Ä {x + 1}'
                )

                fig = px.scatter(
                    viz_df,
                    x='X',
                    y='Y',
                    color='–ö–ª–∞—Å—Ç–µ—Ä',
                    title='–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ DBSCAN',
                    color_discrete_sequence=px.colors.qualitative.Set2,
                    hover_data={'–ö–ª–∞—Å—Ç–µ—Ä': True}
                )

                fig.update_layout(
                    height=600,
                    legend_title_text='–ö–ª–∞—Å—Ç–µ—Ä—ã'
                )

                st.plotly_chart(fig, use_container_width=True)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º")

                cluster_stats = analyzer.get_cluster_statistics()
                if cluster_stats is not None:
                    st.dataframe(cluster_stats, use_container_width=True)

                    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                    fig = px.bar(
                        cluster_stats,
                        x='–ö–ª–∞—Å—Ç–µ—Ä',
                        y='–†–∞–∑–º–µ—Ä',
                        color='–ö–ª–∞—Å—Ç–µ—Ä',
                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º',
                        text='–†–∞–∑–º–µ—Ä'
                    )

                    fig.update_layout(
                        height=500,
                        xaxis_tickangle=-45
                    )

                    st.plotly_chart(fig, use_container_width=True)

                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
                st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º")

                selected_feature = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:",
                    options=analyzer.data_processed.columns.tolist(),
                    key="cluster_feature"
                )

                if selected_feature:
                    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è box plot
                    box_data = []
                    for cluster_id in np.unique(analyzer.labels):
                        indices = np.where(analyzer.labels == cluster_id)[0]
                        if len(indices) > 0:
                            cluster_name = '–®—É–º' if cluster_id == -1 else f'–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}'
                            values = analyzer.data_processed[selected_feature].iloc[indices]

                            for val in values:
                                box_data.append({
                                    '–ö–ª–∞—Å—Ç–µ—Ä': cluster_name,
                                    '–ó–Ω–∞—á–µ–Ω–∏–µ': val,
                                    '–ü—Ä–∏–∑–Ω–∞–∫': selected_feature
                                })

                    box_df = pd.DataFrame(box_data)

                    fig = px.box(
                        box_df,
                        x='–ö–ª–∞—Å—Ç–µ—Ä',
                        y='–ó–Ω–∞—á–µ–Ω–∏–µ',
                        color='–ö–ª–∞—Å—Ç–µ—Ä',
                        title=f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {selected_feature} –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º'
                    )

                    fig.update_layout(
                        height=500,
                        xaxis_tickangle=-45
                    )

                    st.plotly_chart(fig, use_container_width=True)


                st.subheader("–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


                results_df = analyzer.data.copy()
                results_df['–ö–ª–∞—Å—Ç–µ—Ä_DBSCAN'] = analyzer.labels
                results_df['–ö–ª–∞—Å—Ç–µ—Ä_DBSCAN'] = results_df['–ö–ª–∞—Å—Ç–µ—Ä_DBSCAN'].apply(
                    lambda x: '–®—É–º' if x == -1 else f'–ö–ª–∞—Å—Ç–µ—Ä {x + 1}'
                )


                csv = results_df.to_csv(index=False).encode('utf-8')

                col1, col2, col3 = st.columns(3)
                with col2:
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏",
                        data=csv,
                        file_name="clustering_results.csv",
                        mime="text/csv",
                        key="download_results"
                    )


                if st.button("üîÑ –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", key="reset_analysis"):

                    for key in list(st.session_state.keys()):
                        if key != 'file_name':
                            del st.session_state[key]


                    analyzer.load_data("temp_demo.csv" if st.session_state.file_name == "demo_data.csv" else None)
                    st.session_state.data_loaded = True
                    st.rerun()

if __name__ == "__main__":
    main()
